import static
import debug
from mpi4py import MPI
import data
import dirac
import logging
import socket
import os.path as op
import os
import boto
import bisect
import itertools
import pandas
import numpy as np

class Worker:
    """
    tcdirac worker class
    """
    def __init__(self, comm, working_dir, working_bucket, ds_bucket, logging_level=logging.INFO):
        self._comm = comm

        #create a communicators specific to each host
        self._host_comm, self._host_map = self._hostConfig()

        self._initLogging(logging_level)

        self._datasource_bucket = ds_bucket
        self._working_dir = working_dir
        self._working_bucket = working_bucket
        logging.info("Initial settings: working_dir[%s], working bucket [%s], datasource bucket [%s]" 
            % (working_dir, working_bucket, ds_bucket))

        #variables set elseware
        self._nominal_alleles = {}
        self._sd = None #data.SourceData object
        self._mi = None #data.MetaInfo
        self._results = {}

        self._pathways = None
        self._initData()


        
    def _initLogging(self, level=logging.INFO):
        """
        Initialize logging
        """
        comm = MPI.COMM_WORLD
        logfile = "/scratch/sgeadmin/log_mpi_r%i.txt"%comm.Get_rank()
        log_format = '%(asctime)s - %(name)s rank['+str( comm.Get_rank() )+']- %(levelname)s - %(message)s'
        logging.basicConfig(filename=logfile, level=level, format=log_format)


    def _initData(self, data_master=0):
        """
        Parses data (sourcedata and metainfo) and distributes it to all nodes in comm
        """
        comm = self._comm

    
        self.makeDirs([self._working_dir])
        self._getDataFiles(data_master)

        sd = data.SourceData()
        mi = None
        if comm.rank == data_master:
            logging.info('init SourceData')
            sd.load_dataframe()
            sd.load_net_info()
            logging.info('init MetaInfo')
            mi = data.MetaInfo(op.join(self._working_dir,'metadata.txt'))
        logging.info("Broadcasting SourceData and MetaInfo")
        sd = comm.bcast(sd)
        mi = comm.bcast(mi)
        logging.info("Received SourceData and MetaInfo")
     
        self._sd = sd
        self._mi = mi

    def _getDataFiles(self,file_master=0):
        """
        Retrieves metadata and parsed dataframe files
            (generated by utilities/hddata_process.py) from S3
        """
        comm = self._comm
        working_dir = self._working_dir
        data_source_bucket = self._datasource_bucket

        if comm.rank == file_master:
            if not op.exists(op.join( working_dir,'metadata.txt')):
                conn = boto.connect_s3()
                b = conn.get_bucket(data_source_bucket)
                k.key = 'metadata.txt'
                k.get_content_to_filename(op.join( working_dir,'metadata.txt'))

        if comm.rank == file_master:
            if not op.exists(op.join( working_dir, 'trimmed_dataframe.pandas')):
                conn = boto.connect_s3()
                b = conn.get_bucket(data_source_bucket)
                k.key ='trimmed_dataframe.pandas'
                k.get_content_to_filename(op.join( working_dir,'trimmed_dataframe.pandas'))
        comm.barrier()


    def _hostConfig(self):
        """
        Creates a host communicator object and a map from hostnames to hostmasters
        """
        comm = self._comm

        myh = socket.gethostname()
        myr = comm.rank
       
        hlist=comm.gather((myh,myr))
        
        hlist = comm.bcast(hlist) 
        hlist.sort()
        hm = self._host_map = {}
        h_counter = 0
        
        for h,r in hlist:
            if h not in hm:
                hm[h] = (r,h_counter)
                #smallest rank in host is boss
                h_counter += 1
        host_comm = comm.Split( hm[myh][1] )
        host_comm.name = myh

        if host_comm.rank == 0:
            #check that our host master is equal to
            #what we expect
            assert(hm[myh][0] == self._comm.rank)
        return (host_comm, hm)
        

    def isHostMaster(self):
        """
        Returns true if is the smallest rank on the host machine
        """
        return self._host_comm.rank == 0

    def checkDebug(self):
        """
        Prepares host for debug mode if required
        """
        if debug.DEBUG:
            logging.info('***DEBUG ON***')
            makeDirs([debug.debug_dir])


    def makeDirs(self, dirs):
        comm = self._comm
        if self.isHostMaster():
            logging.info('Boss of %s'%socket.gethostname())
            for d in dirs:
                if not op.exists(d):
                    logging.info("Creating [%s]"%d)
                    os.makedirs(d)
        comm.barrier()

       
    def kNearest(self,compare_list,samp_name, samp_age, k):
        """
        Given compare_list, which contains tuples in sorted order
            of (sample_age, sample_name).
        returns k sample names that are closest in age to samp_age
        """
        off = k/2
        i = bisect.bisect_left(compare_list,(age,samp) )
        l = i - off
        u = i + off
        if l < 0:
            u = u - l
            l = 0
        if u >= len(compare_list):
            l = l - (u - (len(compare_list) - 1))
            u = len(compare_list) - 1

        samp_compare = [s for a,s in compare_list[l:u+1]]
        return samp_compare

    def getAlleles(self, cstrain):
        if cstrain not in self._nominal_alleles:
            self._nominal_alleles[cstrain] = self._mi.getNominalAlleles(cstrain)
        return self._nominal_alleles[cstrain]

    def getStrains(self, comm=None, strain_master=0):
        strains = None
        if comm is None:
            comm = self._comm
        if comm.rank == strain_master:
            strains = self._mi.getStrains()
        #making sure everyone is on the same page
        return comm.bcast(strains, root=strain_master)
        
 
    def _getPathways(self, comm=None, pathway_master=0):
        pws = None
        if comm is None:
            comm = self._comm
        if comm.rank == pathway_master:
            pws = self._sd.getPathways()
            #dbase hit, so limit conns
            pws.sort()
        return comm.bcast(pws, root=pathway_master)

    def _getSamplesByStrain(self, strain):
        """
        Returns a list of all sample ids belonging to strain
        """
        return self._mi.getSampleIDs(strain)

    def getMyPathways(self,comm=None):
        if comm == None:
            comm = self._comm 
        if self._pathways is None:
            pathways = self._pathways = self._getPathways( comm )
        else:
            pathways = self._pathways
        return [pw for i,pw in enumerate(pathways) if i%comm.size == comm.rank]

    def initRMSDFrame(self,my_pathways, cstrain, comm=None):
        if comm==None:
           comm = self._comm
        alleles = self.getAlleles(cstrain)
        samples = self._getSamplesByStrain(cstrain)
        indexes = ["%s_%s" % (pw,allele) for pw,allele in  itertools.product(my_pathways, alleles)]
        return pandas.DataFrame(np.empty(( len(indexes), len(samples)), dtype=float), index=indexes, columns=samples)


    def _partitionSamplesByAllele(self, cstrain):
        """
        Get a dictionary of lists of sample names and ages partitioned by allele in increasing
            age order.
        Given alleles(list of strings), mi(metadataInfo object), cstrain (string: current strain)
        returns dict[allele] -> list:[(age_1,samp_name_1), ... ,(age_n,samp_name_n)] sorted by age
        """
        mi = self._mi

        samples = {}
        for allele in self.getAlleles(cstrain):
            samples[allele] = [(mi.getAge(sample),sample)for sample in mi.getSampleIDs(cstrain,allele)]
            samples[allele].sort()
        self._sample_x_allele = samples 

    def initStrain(self, cstrain, mypws):
        self._cstrain = cstrain
        self._partitionSamplesByAllele(cstrain)
        self._results[cstrain] = self.initRMSDFrame( mypws, cstrain )

    def getSamplesByAllele(self, cstrain, allele):
        assert( cstrain == self._cstrain )
        return self._sample_x_allele[allele]

    def genSRTs(self, cstrain, pw):
        srts = {}
        sd = self._sd
        mi = self._mi
        for allele in self.getAlleles(cstrain):
            samples = [s for a,s in self._sample_x_allele[allele]]
            expFrame = sd.getExpression( pw, samples)
            srts[allele] = dirac.getSRT( expFrame )
        return srts

    def getRMS(self, rt, srt):
        return dirac.getRMS( srt, rt )

    def setRMS(self, rms, index, samp):
        self._results[self._cstrain][samp][index] = rms

    def saveRMS(self,prefix='rms'):
        for strain, table in self._results.iteritems():
            ofile_name = '%s.%s.%i.pandas.pkl' % (prefix,strain,self._comm.rank)
            table.to_pickle(op.join(self._working_dir,ofile_name))

if __name__ == "__main__":
    world_comm = MPI.COMM_WORLD

    worker_settings = {
                'comm':MPI.COMM_WORLD, 
                'working_dir':'/scratch/sgeadmin/hddata/', 
                'working_bucket':'hd_working_0', 
                'ds_bucket':'hd_source_data', 
                'logging_level':logging.INFO
                }
    k_neighbors = 5

    #a dictionary to hold the result dataframes, keyed by strain
    results = {}

    wkr = Worker(**worker_settings)     
    for cstrain in wkr.getStrains():
        logging.info("Strain[%s] starting" % cstrain)

        mypws = wkr.getMyPathways()
        alleles = wkr.getAlleles(cstrain)
        wkr.initStrain(cstrain, mypws)
        for pw in mypws:
            srts = wkr.genSRTs( cstrain, pw )
            for a_base, a_compare in itertools.product(alleles,alleles):
                r_index = "%s_%s" % (pw, a_compare)
                base_samp = wkr.getSamplesByAllele(cstrain, a_base)
                comp_samp = wkr.getSamplesByAllele(cstrain,a_compare)
                for age, samp in base_samp:
                    neighbors = wkr.kNearest(comp_samp, samp, age, k_neighbors)
                    srt_comp = srts[a_compare].loc[:,neighbors]
                    rt = dirac.getRT(srt_comp) 
                    samp_srt = srts[a_base][samp]
                    rms = wkr.getRMS( rt, samp_srt ) 
                    wkr.setRMS(rms, r_index, samp)
    wkr.saveRMS()        
