from mpi4py import MPI
import logging
import data
import debug
import os.path as op
class Worker:
    """
    tcdirac worker class
    """
    def __init__(self, comm, working_dir, working_bucket, ds_bucket, logging_level=logging.INFO):
        self._comm = comm
        self._host_comm, self._host_map = self._hostConfig()

        self._initLogging(logging_level)

        self._datasource_bucket = ds_bucket
        self._working_dir = working_dir
        self._working_bucket = working_bucket
        logging.info("Initial settings: working_dir[%s], working bucket [%s], datasource bucket [%s]" 
            % (working_dir, working_bucket, ds_bucket))
        self._nominal_alleles = {}
        self._sd = None #data.SourceData object
        self._mi = None #data.MetaInfo
        self._host_master = self._host_comm.rank == 0
        self._initData()


        
    def _initLogging(self, level=logging.INFO):
        """
        Initialize logging
        """
        comm = MPI.COMM_WORLD
        logfile = "/scratch/sgeadmin/log_mpi_r%i.txt"%comm.Get_rank()
        log_format = '%(asctime)s - %(name)s rank['+str( comm.Get_rank() )+']- %(levelname)s - %(message)s'
        logging.basicConfig(filename=logfile, level=level, format=log_format)


    def _initData(self, data_master=0):
        """
        Parses data (sourcedata and metainfo) and distributes it to all nodes in comm
        """
        comm = self._comm

    
        self.makeDirs([self._working_dir])
        self._getDataFiles(data_master)

        sd = data.SourceData()
        mi = None
        if comm.rank == data_master:
            logging.info('init SourceData')
            sd.load_dataframe()
            sd.load_net_info()
            logging.info('init MetaInfo')
            mi = data.MetaInfo(op.join(working_dir,'metadata.txt'))
        logging.info("Broadcasting SourceData and MetaInfo")
        sd = comm.bcast(sd)
        mi = comm.bcast(mi)
        logging.info("Received SourceData and MetaInfo")
     
        self._sd = sd
        self._mi = mi

    def _getDataFiles(self,file_master=0):
        """
        Retrieves metadata and parsed dataframe files
            (generated by utilities/hddata_process.py) from S3
        """
        comm = self._comm
        working_dir = self._working_dir
        data_source_bucket = self._data_source_bucket

        if comm.rank == file_master:
            if not op.exists(op.join( working_dir,'metadata.txt')):
                conn = boto.connect_s3()
                b = conn.get_bucket(data_source_bucket)
                k.key = 'metadata.txt'
                k.get_content_to_filename(op.join( working_dir,'metadata.txt'))

        if comm.rank == file_master:
            if not op.exists(op.join( working_dir, 'trimmed_dataframe.pandas')):
                conn = boto.connect_s3()
                b = conn.get_bucket(data_source_bucket)
                k.key ='trimmed_dataframe.pandas'
                k.get_content_to_filename(op.join( working_dir,'trimmed_dataframe.pandas'))
        comm.barrier()


    def _hostConfig(self):
        """
        Creates a host communicator object and a map from hostnames to hostmasters
        """
        comm = self._comm

        myh = socket.gethostname()
        myr = comm.rank
       
        hlist=comm.gather((myh,myr))
        
        hlist = comm.bcast(hlist) 
        hlist.sort()
        hm = self._host_map = {}
        h_counter = 0
        
        for h,r in hlist:
            if h not in hm:
                hm[h] = (r,h_counter)
                #smallest rank in host is boss
                h_counter += 1
        host_comm = comm.Split( hm[myh][1] )
        host_comm.name = myh

        if host_comm.rank == 0:
            #check that our host master is equal to
            #what we expect
            assert(hm[myh][0] == self._comm.rank)
        return (host_comm, hm)
        

    def isHostMaster(self):
        """
        Returns true if is the smallest rank on the host machine
        """
        return self._host_comm.rank == 0

    def checkDebug(self):
        """
        Prepares host for debug mode if required
        """
        if debug.DEBUG:
            logging.info('***DEBUG ON***')
            makeDirs([debug.debug_dir])


    def makeDirs(self, dirs):
        comm = self._comm
        if self.isHostMaster():
            logging.info('Boss of %s'%socket.gethostname())
            for d in dirs:
                if not op.exists(d):
                    logging.info("Creating [%s]"%d)
                    os.makedirs(d)
        comm.barrier()

       
    def kNearest(compare_list,samp_name, samp_age, k):
        """
        Given compare_list, which contains tuples in sorted order
            of (sample_age, sample_name).
        returns k sample names that are closest in age to samp_age
        """
        off = k/2
        i = bisect.bisect_left(compare_list,(age,samp) )
        l = i - off
        u = i + off
        if l < 0:
            u = u - l
            l = 0
        if u >= len(compare_list):
            l = l - (u - (len(compare_list) - 1))
            u = len(compare_list) - 1

        samp_compare = [s for a,s in compare_list[l:u+1]]
        return samp_compare

    def _getAlleles(self, cstrain):
        if cstrain not in self._nominal_alleles:
            self._nominal_alleles[cstrain] = self._mi.getNominalAlleles(cstrain)
        return self._nominal_alleles[cstrain]

    def _getStrains(self, comm=None, strain_master=0):
        strains = None
        if comm is None:
            comm = self._comm
        if comm.rank == strain_master:
            strains = self._mi.getStrains()
        #making sure everyone is on the same page
        return comm.bcast(strains, root=strain_master)
        
 
    def _getPathways(self, comm=None, pathway_master=0):
        pws = None
        if comm is None:
            comm = self._comm
        if comm.rank == pathway_master:
            pws = self._sd.getPathways()
            #dbase hit, so limit conns
            pws.sort()
        return comm.bcast(pws, root=pathway_master)

    def _getSamplesByStrain(self, strain):
        """
        Returns a list of all sample ids belonging to strain
        """
        return self._mi.getSampleIDs(strain)

    def _getMyPathways(self,pathways, comm=None):
        if comm == None:
            comm = self._comm 

        return [pw for i,pw in enumerate(pathways) if i%comm.size == comm.rank]

    def initRMSDFrame(self,my_pathways, cstrain):
        if comm==None:
           comm = self._comm
        alleles = self._getAlleles(cstrain)
        indexes = ["%s_%s" % (pw,allele) for pw,allele in  itertools.product(my_pathways, alleles)]
        return pandas.DataFrame(np.empty( len(indexes), len(samples)), dtype=float), index=indexes, columns=samples)


    def _partitionSamplesByAllele(self, alleles, cstrain):
        """
        Get a dictionary of lists of sample names and ages partitioned by allele in increasing
            age order.
        Given alleles(list of strings), mi(metadataInfo object), cstrain (string: current strain)
        returns dict[allele] -> list:[(age_1,samp_name_1), ... ,(age_n,samp_name_n)] sorted by age
        """
        mi = self._mi

        samples = {}
        for allele in alleles:
            samples[allele] = [(mi.getAge(sample),sample)for sample in mi.getSampleIDs(cstrain,allele)]
            samples[allele].sort()
        self._sample_x_allele = samples 


if __name__ == "__main__":
    world_comm = MPI.COMM_WORLD

    worker_settings = {
                'comm':MPI.COMM_WORLD, 
                'working_dir':'/scratch/sgeadmin/hddata/', 
                'working_bucket':'hd_working_0', 
                'ds_bucket':'hd_source_data', 
                'logging_level':logging.INFO
                }

    wkr = Worker(**worker_settings)     
    

